next steps:

1. find out from literature what aspects concern survey questions
2. think about how theses different aspects can be automatically encoded by pre-trained language models
3. generate synthetic questions to see if these aspects are captured
4. think about how to make a language model for survey questions
5. perhaps this can be used for the bigbench project as well


6. perhaps we can use survey embeddings for SQP
7. other automatic, objective metrics: comprehensibility, readability
8. 


Decisions to make to design a survey
1. choice of a topic
2. choice of the most important variables
3. choice of a data collection method
4. choice of operationalization
5. test of the quality of the questionnaire
6. formulation of the final questionnaire
7. choice of population and sample design
8. decide about the fieldwork

Decisions to make a survey question (under choice of operationalization)
1. subject and dimension
2. formulation of the question
3. the response categories
4. additional text

Concepts by intuition (intuitive, simple concepts) vs. concepts by postulation (complex concepts, or, constructs)

Three steps for the design of questions:
1. specification of the concept-by-postulation in concepts-by-intuition
2. transformation of concepts-by-intuition in statements indicating the requested concepts
3. transformation of statements into questions


About the validity project, perhaps it makes sense to distinguish the quality of the prediction in terms of correlation and absolute values.

forms of sentences:
declarative sentences: assertions
interrogative sentences: requests
imperative sentences: orders
exclamations (not used in survey research)

sentences can be divided into sentence constituents or phrases and their syntactic functional components.


basic concepts-by-intuition for subjective variables: evaluations, importance judgments, feelings, cognitive judgments, perceived relationships between x and y, evaluative beliefs, preferences, norms, policies, rights, action tendencies, and expectations of future events.

assertions for which the meaning is not so clear: evaluative beliefs

concepts-by-intuition for objective variables: behaviour, events, time, place, quantities, procedures, demographic variables, and knowledge.

extensions to simple sentences: adding indirect objects, adding modifiers, adding adverbials

two basic choices for formulating a request: the use of direct or indirect requests; whether to use WH word

direct request: direct instruction; direct request
indirect request: Imperative每Interrogative Requests, Interrogative每Interrogative Requests; Declarative每Interrogative, Interrogative每Declarative


meaning of requests: when, who, which, what, and how

steps of developing a request: first, decide what needs to be studied; second, specify typical assertions; third, transform these assertions into requests for an answer.

in addition to research goal and concepts, other characteristics: time reference, social desirability, saliency or centrality. 

problematic requests: double-barreled, requests with implicit assumptions

batteries of requests for answers: introduction, the general request, eventual components (such as instructions), stimulus or statement.




task 1: the linguistic meaning form of sentences
task 2: structure (NP + VP etc.)
task 3: elements of assertions  
task 4: type of concepts-by-intuition
task 5: where the emphasis is
task 6: extensions of simple sentences
task 7: complex versus simple sentences
task 8: distinguish between structures of a battery or a request



for the meeting:
1. what i have been doing
2. paper structure suggestion
2a. a tutorial on how to use sentence embeddings for surveys
2b. 
3. proposal: a system to generate survey questions; a language model for survey questions; an experiment to collect data (to verify some of our results)
4. some thoughts: probably we need more demographic variables to be able to predict responses

questions:
1. are there language models that focus on the more syntactic aspects of texts?
2. what do we do about complex questions?
3. there are two ways: just check cosine similarities; or use a shallow linear model to check prediction on the subtasks. 
4. should we generate the test questions separately? in the sense that we focus on testing one aspect at a time. 
5. do we want sentence embeddings to just focus on the semantics (concept)? or do we also want them to capture the other aspects of survey questions?
6. how do you represent the response scale
7. we focus specifically on web survey questions


Presentation in the meeting:
1. notes from the last meeting (i didn't finetune the models yet but i set up hpc)
2. the book
3. the paper structure
4. the synthetic questions can be used to


1. Update the readme.txt for hpc
2. cosine similarity might be hard to interpret; perhaps there is a better measure; it does not necessarily measure what we want, or connect to the final prediction outcome; what does cosine similarity measure? which part of the change explains the similarity? explain which aspect of the embeddings explains what? PCA? amnesic probing?
3. survey item reliability: ESS, item code, estimates of the reliability (validity). But put the focus on a. 
4. baseline: ask social scientists how people would respond to a survey question
5. perhaps just look at categorised responses: low, middle, high; or just look at the correlations
6. if the conclusion is that response prediction is difficult, then all the more reasons to use surveys
7. use the generated questions in SQP
8. how to make synthetic questions
9. ask teaching (els, gerko)
10. make an open task: predict responses to new questions

Kees
the other NLP group

discriminative model vs. conditional generative model
delta function, sifting property
underspecified




fairness
can't you just do a more specific search
and representation of what? race? gender? height? age?
research in what sensitive attributes are important?
possible that by stressing certain sensitive attributes, you hurt groups that are not included in those sensitive attributes?
any research on how this approach relates to overall more equality?



types of harms
- allocative harms
- representational harms

If we would have all the data, we would only address the statistical bias problem.
No data sets are free of societal biases.

bias preserving system vs. bias transforming system
- equal opportunity vs. demographic parity


page 1, 3, 4, 6, 7, 8, 9, 12, 13, 14, 15, 16, 23, 26


references: singer1993, SingerHoewyk2003

replace words like explain and explanation
the term: survey response?
check the term appendix 

Department of Methodology and Statistics, Faculty of Social and Behavioural Sciences, Sjoerd Groenmangebouw, Padualaan 14, 3584 CH Utrecht, The Netherlands


Questions to Kees:
- anything from thursday's meeting? how was the discussion?
- would people appreciate a tuturial paper on how and when to use statistical tests?
- my work
- how do you see the connection between my work (survey question answering) and question answering 
- how does my work relate to others?
- how about the other NLP group?



20210315 MTMM Task
- more features (capitalization, exclamation, average word/sentence length, POS, emotions, topic modelling)

- add features to the RF function
-- save model 
-- save y_pred
-- calculate r-squared
-- calculate correlations

- change the task setting
-- classification



the amount of personal opinion and factual information contained in the text














Places in Houten:
- Galerijmuur
- Boogmuur
- Bluswater
- Center Castellum
- Bronmos
- Kantmos
- Edelsteen